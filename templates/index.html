<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIDS Dataset Repository</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='styles.css') }}">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.10.377/pdf.min.js"></script>
    <script src="{{ url_for('static', filename='script.js') }}" defer></script>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>


</head>
<body>
    <header style="
    color: #f8f0f0; 
    background-color: black; 
    border-color: rgb(136, 136, 136); 
    padding-top: 5px; 
    display: flex; 
    justify-content: center; 
    align-items: center; 
    text-align: center;
    height: 80px;">
        <h1>Multimodal Educational Video Dataset - Neural Engineering Lab, CCNY</h1>
    </header>

    <header style="color: #f8f0f0; background-color: #1e2760; border-color: rgb(136, 136, 136); padding-top: 2px;">
        <nav>
            <ul style="list-style: none; display: flex; padding: 0; margin: 0;">
                <li style="margin-right: 10px;">
                    <a href="{{ url_for('index') }}" class="nav-link">Home</a>
                </li>
                <li>|</li>
                <li style="margin-right: 10px;">
                    <a href="{{ url_for('experiments_page') }}" class="nav-link">Experiments</a>
                </li>
                <li>|</li>
                <li style="margin-right: 10px;">
                    <a href="{{ url_for('questionnaires_page') }}" class="nav-link">Questionnaires</a>
                </li>
                <li>|</li>
                <li style="margin-right: 10px;">
                    <a href="{{ url_for('tutorials_page') }}" class="nav-link">Tutorials</a>
                </li>
                <li>|</li>
                <li style="margin-right: 10px;">
                    <a href="{{ url_for('research_page') }}" class="nav-link">Research</a>
                </li>
                <li>|</li>
                <li style="margin-right: 10px;">
                    <a href="{{ url_for('about_page') }}" class="nav-link">About</a>
                </li>
                <li>|</li>
                <li style="margin-right: 10px;">
                    <a href="{{ url_for('download_page') }}" class="nav-link">Download</a>
                </li>
            </ul>
        </nav>
    </header>

    <main>
        <div class="flex-container"> 
            <div>
                <section id="container-heading" >
                    <h2>Brief Overview</h2>
                </section>

                <section id="plot-display">
                    <div id="container-content">
                        <h2><u>Summary</u></h2>
                        <div >
                            In each of the 5 experiments:
                            <ul>
                                <li>Subjects watch different video stimuli in <u>attention</u> and <u>distracted</u> (or <u>intervention</u>) conditions
                                <li>They answer questions about the videos to assess memory and engagement.
                                <li>Multimodal physiological data is collected throughout.
                                <li>Both raw and preprocessed data alignes across all modalities are available.</li>
                            </ul>
                        </div>
                        <div class="image-container">
                            <img src="static/images/watchandanswer.jpg" style="width: 480px; height: 200px;">
                        </div>

                        <h2><u>Dataset at a Glance</u></h2>
                        <ul>
                            <li><strong>Number of Experiments:</strong> 5</li>
                            <li><strong>Total Subjects:</strong> 178</li>
                            
                            <br>
                            <li><strong>Total Raw Modalities:</strong> 7</li>
                            <ul>
                                <li>EEG | ECG | EOG | Respiration | Eyetracking (Pupil Size, Gaze and Head Coordinates)</li>
                            </ul>
                            <br>
                            <li><strong>Total Hours of Raw Data:</strong></li>
                            <table>
                                <br>
                                <tr>
                                    <th></th>
                                    <th>EEG</th>
                                    <th>ECG</th>
                                    <th>Head</th>
                                    <th>Eyetracking</th>
                                    <th>Respiration</th>
                                </tr>
                                <tr>
                                    <th>Quantity</th>
                                    <td>67.3 hours</td>
                                    <td>67.1 hours</td>
                                    <td>68.5 hours</td>
                                    <td>88.6 hours</td>
                                    <td>23.9 hours</td>
                                </tr>
                            </table>
                            <br>
                            <li><strong>Total Derived Modalities:</strong> 12</li>
                            <ul>
                                <li><u>Continuous</u> - Heart Rate | Breath Rate | Saccade Rate | Blink Rate | Gaze-Fixation Rate </li>
                                <li><u>Discrete</u> - Heart Beats | Breath Peaks | Saccades | Blinks | Gaze-Fixations</li>
                                <li><u>Preprocessed</u> - Filtered ECG | Filtered EEG</li>
                            </ul>
                            <br>
                            <li><strong>Phenotypes Available:</strong> 4</li>
                            <ul>
                                <li>Participant Info (Sex | Age | Occupation | Tired | Study Time | GPA | Last Caffeine Intake | Occupation Field) </li>
                                <li>ASRS (Adult ADHD Self Report) Responses | Digit Span Responses | Stimuli Questionnaire Responses</li>
                            </ul>
                        </ul>
                        
                    </div>
                </section>
            </div>   

            <div>
                <div id="hometable-container"></div>
            </div>

            
        </div>

        <section id="content-heading">
            <h2 id="dataset-message">Data Visualisation | Viewing Experiment 4 Data</h2>
            <p>
                <section>
                    <div id="options-buttons">
                        <div id="subjects"></div>
                        <div id="sessions"></div>
                        <div id="stimuli"></div>
                        <!-- Buttons will be populated dynamically -->
                        <div id="loading" style="display: none; text-align: center; color: white;">
                            <p>Loading...</p>
                        </div>
                    </div>
                </section>
            </p>
        </section>

        <div class="flex-container"> 
            
            <div>
                <section id="plot-display">
                    <p><strong>Raw Signals</strong></p>
                    <div id="plotraw"></div>
                </section>

            </div>

            <div>

                <section id="plot-display">
                    <p><strong>Derived Signals</strong></p>
                    <div id="plotderived"></div>
                </section>

            </div>

        </div>

        <section id="superexp-heading">
            <h2>Potential Dataset Use Cases</h2>
        </section>

        <section id="exp-content">
            <p>
                This multimodal physiological signal dataset offers insights in various research areas, such as:
            </p>
            <ul>
                <li><u><strong>Cognitive Load Assessment</strong></u> - Understanding how different stimuli affect mental effort.</li>
                <li><u><strong>Engagement/Emotional Response Analysis</strong></u> - Measuring how interactive or engaging educational videos are.</li>
                <li><u><strong>Memory Retention Studies</strong></u> - Investigating how well information is retained after viewing.</li>
                <li><u><strong>Interactivity Evaluation</strong></u> - Assessing the effectiveness of stimuli in holding attention.</li>
                <li><u><strong>Multimodal Predictive Modeling</strong></u> - Leveraging synchronized data to predict physiological responses, 
                    such as estimating heart rate from gaze patterns or deriving breath rate from EEG signals, enabling cross-modal insights and applications.</li>
            </ul>
        </section>

        <section id="superexp-heading">
            <h2>Usage Notes</h2>
        </section>
        <section id="exp-content">
            <ol>
                <li>
                    <strong>Acknowledgment:</strong>
                    <p>Cite this dataset in your research and acknowledge its contribution to your studies.</p>
                </li>
                <br>
                <li>
                    <strong>File Formats and Tools:</strong>
                    <br><br>
                    <ul>
                        <li><strong>EEG Data:</strong>
                            <p>
                                - Stored in <code>.bdf</code> format. <br>
                                - Requires Python's <code>"pyEDFlib"</code> library or MATLAB's <code>"EEGLAB"</code> software for processing.
                            </p>
                        </li>
                        <li><strong>Physiological Recordings:</strong>
                            <p>
                                - Provided as compressed <code>.tsv</code> (tab-separated value) files. <br>
                                - Can be opened with spreadsheet applications if you don’t intend to use programming languages.
                            </p>
                        </li>
                    </ul>
                </li>
            </ol>
            <br>
            <p>
                We encourage researchers to explore and utilize this dataset for advancing knowledge in cognitive and physiological sciences.
            </p>
        </section>
        
    </main>
    
    <footer>
        <p>&copy; 2024 Neural Engineering Lab Dataset Repository. All Rights Reserved.</p>
    </footer>
</body>
</html>



        <!-- <section id="content-heading">
            <h2>BIDS Datasets - Brain Imaging Data Structure</h2>
        </section>

        <div class="flex-container"> 
            <div>
                <section id="container-heading">
                    <h2>BIDS Overview</h2>
                </section>
                <section id="plot-display">
                    <div id="container-content">
                    
                        <h1>Understanding BIDS:</h1>
                        <p>
                            The Brain Imaging Data Structure (BIDS) is an internationally recognized standard designed to make organizing, sharing, and analyzing neuroimaging data easy and accessible. BIDS brings structure to otherwise complex and multi-modal data sets by providing a consistent and intuitive directory format that researchers can easily navigate.
                        </p>
                        <p>
                            Our datasets are fully converted into the BIDS format, and are available for download as zip files, ensuring that the data is both well-organized and compatible with various neuroimaging tools and pipelines.
                        </p>
                        <h2>BIDS Structure Overview</h2>
                        <p>
                            BIDS organizes data into a straightforward directory structure. Each dataset has files that describe the dataset, its participants, and related metadata - 
                            <strong>dataset_description.json</strong>, <strong>participants.tsv</strong> and <strong>participants.json</strong>,
                            providing essential information about the study and participants to anyone working with the dataset.
                        </p> 

                        
                        <p>
                            Each participant's data is organized by subject (sub-XX) and then further divided into sessions (ses-XX) to accommodate multi-session data collection (some of our experiments had 2 sessions: attentive and distracted). 
                            Inside each session folder, you'll find modality-specific subfolders, such as:
                        </p>
                        <ul>
                            <li>
                                <strong>eeg:</strong> Contains electroencephalogram data files (.bdf), event logs (events.tsv), and additional metadata (.json) that describe the experiment and recording conditions.
                            </li>
                            <li>
                                <strong>beh:</strong> Contains physiological recordings like ECG (electrocardiogram), eye-tracking, and head movement data, stored in compressed .tsv.gz files, with accompanying metadata in .json files.
                            </li>
                        </ul>

                        <p>
                            There is also a <strong>derivatives</strong>directory which contains processed data derived from the raw recordings, such as filtered heart rate data or preprocessed physiological signals, making it easy to work with and apply advanced analyses. 
                            Files in this directory are also stored in the BIDS structure (subject-wise, session-wise, modality-wise).
                        </p>

                        
                        <h2>How to Navigate the BIDS Dataset</h2>
                        <ul>
                            <li>
                                <strong>Top-Level Files:</strong> Files like <strong>dataset_description.json</strong> and <strong>participants.tsv</strong> give you an overview of the study and participants, serving as your starting point when exploring a dataset.
                            </li>
                            <li>
                                <strong>Derivatives Folder:</strong> In this folder, processed data is organized like how raw data is organised in the BIDS directory.
                            </li>
                            <li>
                                <strong>Subject Folders (sub-XX):</strong> Inside these folders, data is organized by individual participants, providing separate directories for each person involved in the study.
                            </li>
                            <li>
                                <strong>Session Folders (ses-XX):</strong> For longitudinal or multi-session studies, session folders contain the raw and derived data for each session, making it easy to track and analyze data collected over time.
                            </li>
                            <li>
                                <strong>Modality-Specific Subfolders:</strong> Each session is further split into subfolders according to data modalities (e.g., EEG, behavior/physio), helping you to quickly locate the data of interest, whether it’s brain recordings, heart rate data, or eye movement information.
                            </li>
                            <li>
                                <strong>Tasks:</strong> 
                                Each subject is exposed to different stimuli during data collection, and BIDS uses "tasks" in filenames to clearly differentiate recordings based on these experimental conditions. 
                                This makes it easy to identify, retrieve, and analyze data associated with specific tasks across multiple modalities. 
                            </li>
                        </ul>
                    
                    </div>
                </section>
            </div>

            <div>
                <section id="container-heading">
                    <h2>BIDS Dataset Download</h2>
                </section>

                <section id="dataset-list">
                    <h2>Datasets:</h2>
                    <ul id="datasets"></ul>
                    <div id="dataset-info">
                        <p>Select a dataset from the list to view details.</p>
                    </div>
                    <button id="download-button" class="btn" style="display: none;">Download BIDS Dataset</button>
                </section>
            </div>
            
        </div> -->
